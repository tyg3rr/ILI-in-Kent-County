{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling Origin Model Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Manipulation\n",
    "# ======================================================\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from os import path\n",
    "import configparser\n",
    "from epiweeks import Week\n",
    "from datetime import date, datetime\n",
    "from calendar import month_name, month_abbr\n",
    "from helper_functions import *\n",
    "import math\n",
    "from skforecast.utils import save_forecaster, load_forecaster\n",
    "\n",
    "# Reading Secrets\n",
    "# ======================================================\n",
    "cfg = configparser.ConfigParser()\n",
    "cfg.read('secrets.ini')\n",
    "ROOT_PATH = path.abspath(cfg.get('default','root'))\n",
    "DATA_PATH = path.join(ROOT_PATH, 'datasets/data')\n",
    "\n",
    "# Modeling\n",
    "# ======================================================\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.ForecasterSarimax import ForecasterSarimax\n",
    "from skforecast.Sarimax import Sarimax\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from skforecast.model_selection import backtesting_forecaster, grid_search_forecaster\n",
    "from skforecast.model_selection_sarimax import backtesting_sarimax, grid_search_sarimax\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\n",
    "from skforecast.ForecasterBaseline import ForecasterEquivalentDate\n",
    "\n",
    "# Warnings Config\n",
    "# ======================================================\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dates train      : 2005-01-16 00:00:00 --- 2015-12-27 00:00:00  (n=572)\n",
      "Dates validacion : 2016-01-03 00:00:00 --- 2017-12-31 00:00:00  (n=105)\n",
      "Dates test       : 2017-12-31 00:00:00 --- 2019-12-29 00:00:00  (n=105)\n"
     ]
    }
   ],
   "source": [
    "# Loading & Manipulating Dataset\n",
    "# ======================================================\n",
    "\n",
    "df = pd.read_csv(path.join(DATA_PATH, 'raw_dataset.csv'))\n",
    "\n",
    "df['epiweek'] = df['epiweek']\\\n",
    "                .map(lambda x: Week.fromstring(str(x)))\n",
    "\n",
    "df['weekstart'] = pd.to_datetime(\n",
    "                                df['epiweek']\\\n",
    "                                .map(lambda x: Week.startdate(x))\n",
    "                                )\n",
    "\n",
    "df.set_index('weekstart', inplace=True)\n",
    "\n",
    "df['epiweek'] = df['epiweek']\\\n",
    "                .map(lambda x: int(str(x)[4:]))\n",
    "\n",
    "col_ordered = (\n",
    "                'cases','visits','GS_cold', \n",
    "                'GS_cough', 'GS_fever', 'GS_flu', \n",
    "                'AWND', 'PRCP', 'SNOW', \n",
    "                'TMAX', 'TMIN', 'TAVG',\n",
    "                'Overall AQI Value',\n",
    "                'CO', 'Ozone', 'PM10', \n",
    "                'PM25', 'Days Good',\n",
    "                'Days Moderate', 'Days Unhealthy'\n",
    "                )\n",
    "\n",
    "means = df[list(col_ordered)].groupby(df.index.month).mean()\n",
    "means.index.name = 'month'\n",
    "df['month'] = df.index.month\n",
    "\n",
    "df = df.reset_index().set_index(['weekstart','month'])\n",
    "\n",
    "df['TAVG'] = df[['TAVG']].fillna(\n",
    "                            pd.DataFrame(\n",
    "                            (df['TMAX'] + df['TMIN']) / 2)\\\n",
    "                            .rename(columns={0:'TAVG'})\n",
    "                                )\n",
    "\n",
    "df[list(col_ordered)] = df[list(col_ordered)].fillna(means)\n",
    "\n",
    "# One-hot encoding 'Main Pollutant'\n",
    "df['Main Pollutant'] = df['Main Pollutant'].astype('category')\n",
    "df = pd.get_dummies(df)\\\n",
    "    .drop(columns=[\"Main Pollutant_['Ozone' 'PM2.5']\"])\n",
    "\n",
    "df = df.astype({col: np.float32 for col in df.select_dtypes(\"number\").columns})\n",
    "\n",
    "epiweek_encoded = cyclical_encoding(df['epiweek'].apply(lambda x: x-1), cycle_length=52)\n",
    "\n",
    "df = pd.concat([df, epiweek_encoded], axis=1)\n",
    "df = df.reset_index()\\\n",
    "    .set_index('weekstart')\\\n",
    "    .drop(columns=['month'])\\\n",
    "    .resample('W').first()\\\n",
    "    .fillna(method='ffill')\n",
    "\n",
    "variables = ['GS_cold', 'GS_cough', 'GS_fever', 'GS_flu', \n",
    "            'AWND', 'PRCP','SNOW', 'TAVG','TMAX', 'TMIN',\n",
    "            'Overall AQI Value', \n",
    "            'CO', 'Ozone', 'PM10', 'PM25', 'Days Moderate', \n",
    "            'Days Unhealthy', 'visits','Main Pollutant_CO', \n",
    "            'Main Pollutant_NO2', 'Main Pollutant_PM2.5']\n",
    "\n",
    "for v in variables:\n",
    "    for i in range(1,4):\n",
    "        df[f'{v}_L{i}'] = df[v].shift(i)\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "end_train, end_validation, df_train, df_val, df_test = train_test_validate_split(\n",
    "                                                        df, end_train = date(2015,12,31), \n",
    "                                                        end_validation = date(2017,12,31)\n",
    "                                                                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-Week Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 104/104 [00:12<00:00,  8.39it/s]\n"
     ]
    }
   ],
   "source": [
    "# elastic net 1-week\n",
    "# ==============================================================================\n",
    "\n",
    "ENF = load_forecaster('ElasticNet_001 hide.py',verbose=False)\n",
    "\n",
    "elasticnet_backtesting_met1, elasticnet_backtesting_preds1 = backtesting_forecaster(\n",
    "    forecaster=ENF,\n",
    "    y=df['cases'],\n",
    "    exog=df[ENF.exog_col_names],\n",
    "    initial_train_size=len(df[:end_validation]),\n",
    "    steps=1,\n",
    "    fixed_train_size=True,\n",
    "    metric='mean_absolute_error',\n",
    "    refit=True,\n",
    "    verbose=False,\n",
    "    show_progress=True\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 104/104 [07:03<00:00,  4.08s/it]\n"
     ]
    }
   ],
   "source": [
    "# random forest 1-week\n",
    "# ==============================================================================\n",
    "\n",
    "RFF = load_forecaster(\"RandomForest_001 hide.py\", verbose=False)\n",
    "\n",
    "randomforest_backtesting_met1, randomforest_backtesting_preds1 = backtesting_forecaster(\n",
    "    forecaster=RFF,\n",
    "    y=df['cases'],\n",
    "    exog=df[RFF.exog_col_names],\n",
    "    initial_train_size=len(df[:end_validation]),\n",
    "    steps=1,\n",
    "    fixed_train_size=True,\n",
    "    metric='mean_absolute_error',\n",
    "    refit=True,\n",
    "    verbose=False,\n",
    "    show_progress=True\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 104/104 [3:57:05<00:00, 136.78s/it]\n"
     ]
    }
   ],
   "source": [
    "# sarimax 1-week\n",
    "# ==============================================================================\n",
    "\n",
    "SMF = load_forecaster('SARIMAX_001 hide.py',verbose=False)\n",
    "\n",
    "sarimax_backtesting_met1, sarimax_backtesting_preds1 = backtesting_sarimax(\n",
    "    forecaster=SMF,\n",
    "    y=df['cases'],\n",
    "    exog=df[SMF.exog_col_names],\n",
    "    initial_train_size=len(df[:end_validation]),\n",
    "    steps=1,\n",
    "    fixed_train_size=True,\n",
    "    metric='mean_absolute_error',\n",
    "    refit=True,\n",
    "    verbose=False,\n",
    "    show_progress=True\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 209/209 [00:00<00:00, 503.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255.94498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# seasonal naive 1-week\n",
    "# ==============================================================================\n",
    "\n",
    "base = load_forecaster('baseline_001 hide.py',verbose=False)\n",
    "\n",
    "mb1, baseline_preds1 = backtesting_forecaster(\n",
    "    forecaster=base,\n",
    "    y=df['cases'],\n",
    "    initial_train_size=len(df_train),\n",
    "    refit=True,\n",
    "    steps=1,\n",
    "    verbose=False,\n",
    "    metric='mean_absolute_error',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving 1-week predictions\n",
    "# ==============================================================================\n",
    "\n",
    "elasticnet_backtesting_preds1.to_csv('elasticnetbacktestingpreds1.csv')\n",
    "sarimax_backtesting_preds1.to_csv('sarimxbacktestingpreds1.csv')\n",
    "randomforest_backtesting_preds1.to_csv('randomforestbacktestingpreds1.csv')\n",
    "baseline_preds1.to_csv('baseline_preds1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-Week Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [00:08<00:00,  6.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# elastic net 2-week\n",
    "# ==============================================================================\n",
    "\n",
    "ENF = load_forecaster('ElasticNet_001 hide.py',verbose=False)\n",
    "\n",
    "elasticnet_backtesting_met2, elasticnet_backtesting_preds2 = backtesting_forecaster(\n",
    "    forecaster=ENF,\n",
    "    y=df['cases'],\n",
    "    exog=df[ENF.exog_col_names],\n",
    "    initial_train_size=len(df[:end_validation]),\n",
    "    steps=2,\n",
    "    fixed_train_size=True,\n",
    "    metric='mean_absolute_error',\n",
    "    refit=True,\n",
    "    verbose=False,\n",
    "    show_progress=True\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [03:06<00:00,  3.59s/it]\n"
     ]
    }
   ],
   "source": [
    "# random forest 2-week\n",
    "# ==============================================================================\n",
    "\n",
    "RFF = load_forecaster(\"RandomForest_001 hide.py\", verbose=False)\n",
    "\n",
    "randomforest_backtesting_met2, randomforest_backtesting_preds2 = backtesting_forecaster(\n",
    "    forecaster=RFF,\n",
    "    y=df['cases'],\n",
    "    exog=df[RFF.exog_col_names],\n",
    "    initial_train_size=len(df[:end_validation]),\n",
    "    steps=2,\n",
    "    fixed_train_size=True,\n",
    "    metric='mean_absolute_error',\n",
    "    refit=True,\n",
    "    verbose=False,\n",
    "    show_progress=True\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [2:14:13<00:00, 154.88s/it]\n"
     ]
    }
   ],
   "source": [
    "# sarimax 2-week\n",
    "# ==============================================================================\n",
    "\n",
    "SMF = load_forecaster('SARIMAX_001 hide.py',verbose=False)\n",
    "\n",
    "sarimax_backtesting_met2, sarimax_backtesting_preds2 = backtesting_sarimax(\n",
    "    forecaster=SMF,\n",
    "    y=df['cases'],\n",
    "    exog=df[SMF.exog_col_names],\n",
    "    initial_train_size=len(df[:end_validation]),\n",
    "    steps=2,\n",
    "    fixed_train_size=True,\n",
    "    metric='mean_absolute_error',\n",
    "    refit=True,\n",
    "    verbose=False,\n",
    "    show_progress=True\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [00:00<00:00, 568.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255.94498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# seasonal naive 2-week\n",
    "# ==============================================================================\n",
    "\n",
    "base = load_forecaster('baseline_001 hide.py',verbose=False)\n",
    "\n",
    "mb2, baseline_preds2 = backtesting_forecaster(\n",
    "    forecaster=base,\n",
    "    y=df['cases'],\n",
    "    initial_train_size=len(df_train),\n",
    "    refit=True,\n",
    "    steps=2,\n",
    "    verbose=False,\n",
    "    metric='mean_absolute_error',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving 2-week predictions\n",
    "# ==============================================================================\n",
    "\n",
    "elasticnet_backtesting_preds2.to_csv('elasticnetbacktestingpreds2.csv')\n",
    "sarimax_backtesting_preds2.to_csv('sarimxbacktestingpreds2.csv')\n",
    "randomforest_backtesting_preds2.to_csv('randomforestbacktestingpreds2.csv')\n",
    "baseline_preds2.to_csv('baseline_preds2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
